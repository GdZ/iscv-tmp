
@article{mur-artal_orb-slam2_2017,
	title = {{ORB}-{SLAM2}: an {Open}-{Source} {SLAM} {System} for {Monocular}, {Stereo} and {RGB}-{D} {Cameras}},
	volume = {33},
	issn = {1552-3098, 1941-0468},
	shorttitle = {{ORB}-{SLAM2}},
	url = {http://arxiv.org/abs/1610.06475},
	doi = {10.1109/TRO.2017.2705103},
	abstract = {We present ORB-SLAM2 a complete SLAM system for monocular, stereo and RGB-D cameras, including map reuse, loop closing and relocalization capabilities. The system works in real-time on standard CPUs in a wide variety of environments from small hand-held indoors sequences, to drones flying in industrial environments and cars driving around a city. Our back-end based on bundle adjustment with monocular and stereo observations allows for accurate trajectory estimation with metric scale. Our system includes a lightweight localization mode that leverages visual odometry tracks for unmapped regions and matches to map points that allow for zero-drift localization. The evaluation on 29 popular public sequences shows that our method achieves state-of-the-art accuracy, being in most cases the most accurate SLAM solution. We publish the source code, not only for the benefit of the SLAM community, but with the aim of being an out-of-the-box SLAM solution for researchers in other fields.},
	number = {5},
	urldate = {2020-06-12},
	journal = {IEEE Transactions on Robotics},
	author = {Mur-Artal, Raul and Tardos, Juan D.},
	month = oct,
	year = {2017},
	note = {arXiv: 1610.06475},
	keywords = {Computer Science - Robotics, Computer Science - Computer Vision and Pattern Recognition},
	pages = {1255--1262},
	annote = {Comment: Accepted for publication in IEEE Transactions on Robotics
https://github.com/raulmur/ORB\_SLAM2.git},
	file = {arXiv Fulltext PDF:/home/zz/Zotero/storage/8HYDNEFF/Mur-Artal and Tardos - 2017 - ORB-SLAM2 an Open-Source SLAM System for Monocula.pdf:application/pdf}
}

@inproceedings{kerl_dense_2013,
	title = {Dense visual {SLAM} for {RGB}-{D} cameras},
	doi = {10.1109/IROS.2013.6696650},
	abstract = {In this paper, we propose a dense visual SLAM method for RGB-D cameras that minimizes both the photometric and the depth error over all pixels. In contrast to sparse, feature-based methods, this allows us to better exploit the available information in the image data which leads to higher pose accuracy. Furthermore, we propose an entropy-based similarity measure for keyframe selection and loop closure detection. From all successful matches, we build up a graph that we optimize using the g2o framework. We evaluated our approach extensively on publicly available benchmark datasets, and found that it performs well in scenes with low texture as well as low structure. In direct comparison to several state-of-the-art methods, our approach yields a significantly lower trajectory error. We release our software as open-source.},
	booktitle = {2013 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Kerl, Christian and Sturm, Jürgen and Cremers, Daniel},
	month = nov,
	year = {2013},
	note = {ISSN: 2153-0866},
	keywords = {cameras, Cameras, Covariance matrices, dense visual SLAM method, depth error minimization, entropy, Entropy, entropy-based similarity measure, g2o framework, graph, graph theory, image texture, keyframe selection, loop closure detection, open-source software, Optimization, photometric error minimization, photometry, RGB-D cameras, Simultaneous localization and mapping, SLAM (robots), Trajectory, Visualization},
	pages = {2100--2106},
	file = {IEEE Xplore Abstract Record:/home/zz/Zotero/storage/7UZRXT93/6696650.html:text/html;Submitted Version:/home/zz/Zotero/storage/9MKKLXYY/Kerl et al. - 2013 - Dense visual SLAM for RGB-D cameras.pdf:application/pdf}
}

@article{davison_monoslam_2007,
	title = {{MonoSLAM}: {Real}-{Time} {Single} {Camera} {SLAM}},
	volume = {29},
	issn = {1939-3539},
	shorttitle = {{MonoSLAM}},
	doi = {10.1109/TPAMI.2007.1049},
	abstract = {We present a real-time algorithm which can recover the 3D trajectory of a monocular camera, moving rapidly through a previously unknown scene. Our system, which we dub MonoSLAM, is the first successful application of the SLAM methodology from mobile robotics to the "pure vision" domain of a single uncontrolled camera, achieving real time but drift-free performance inaccessible to structure from motion approaches. The core of the approach is the online creation of a sparse but persistent map of natural landmarks within a probabilistic framework. Our key novel contributions include an active approach to mapping and measurement, the use of a general motion model for smooth camera movement, and solutions for monocular feature initialization and feature orientation estimation. Together, these add up to an extremely efficient and robust algorithm which runs at 30 Hz with standard PC and camera hardware. This work extends the range of robotic systems in which SLAM can be usefully applied, but also opens up new areas. We present applications of MonoSLAM to real-time 3D localization and mapping for a high-performance full-size humanoid robot and live augmented reality with a hand-held camera},
	number = {6},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Davison, Andrew J. and Reid, Ian D. and Molton, Nicholas D. and Stasse, Olivier},
	month = jun,
	year = {2007},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Cameras, Simultaneous localization and mapping, SLAM (robots), Algorithms, Artificial Intelligence, Pattern Recognition, Automated, Robustness, 3D trajectory, 3D/stereo scene analysis, Autonomous vehicles, Computer Systems, feature extraction, feature orientation estimation, Hardware, humanoid robot, humanoid robots, Image Enhancement, Image Interpretation, Computer-Assisted, image sensors, Imaging, Three-Dimensional, Information Storage and Retrieval, Layout, Mobile robots, monocular camera, MonoSLAM, Motion estimation, Motion measurement, Numerical Analysis, Computer-Assisted, Photogrammetry, Real time systems, real-time single camera SLAM, Robot vision systems, Signal Processing, Computer-Assisted, tracking., Video Recording},
	pages = {1052--1067},
	file = {Submitted Version:/home/zz/Zotero/storage/ZB9QYJBY/Davison et al. - 2007 - MonoSLAM Real-Time Single Camera SLAM.pdf:application/pdf}
}

@inproceedings{klein_parallel_2007,
	title = {Parallel {Tracking} and {Mapping} for {Small} {AR} {Workspaces}},
	doi = {10.1109/ISMAR.2007.4538852},
	abstract = {This paper presents a method of estimating camera pose in an unknown scene. While this has previously been attempted by adapting SLAM algorithms developed for robotic exploration, we propose a system specifically designed to track a hand-held camera in a small AR workspace. We propose to split tracking and mapping into two separate tasks, processed in parallel threads on a dual-core computer: one thread deals with the task of robustly tracking erratic hand-held motion, while the other produces a 3D map of point features from previously observed video frames. This allows the use of computationally expensive batch optimisation techniques not usually associated with real-time operation: The result is a system that produces detailed maps with thousands of landmarks which can be tracked at frame-rate, with an accuracy and robustness rivalling that of state-of-the-art model-based systems.},
	booktitle = {2007 6th {IEEE} and {ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	author = {Klein, Georg and Murray, David},
	month = nov,
	year = {2007},
	keywords = {Cameras, Simultaneous localization and mapping, SLAM (robots), Robustness, Layout, Robot vision systems, Algorithm design and analysis, augmented reality, batch optimisation techniques, Concurrent computing, hand-held camera, Handheld computers, parallel mapping, parallel tracking, robot vision, robotic exploration, SLAM algorithms, Tracking, Yarn},
	pages = {225--234},
	file = {Klein and Murray - 2007 - Parallel Tracking and Mapping for Small AR Workspa.pdf:/home/zz/Zotero/storage/ZF9YC26L/Klein and Murray - 2007 - Parallel Tracking and Mapping for Small AR Workspa.pdf:application/pdf}
}

@inproceedings{engel_semi-dense_2013,
	title = {Semi-dense visual odometry for a monocular camera},
	booktitle = {Proceedings of the {IEEE} international conference on computer vision},
	author = {Engel, Jakob and Sturm, Jurgen and Cremers, Daniel},
	year = {2013},
	pages = {1449--1456},
	file = {Full Text:/home/zz/Zotero/storage/HC3GDRUU/Engel et al. - 2013 - Semi-dense visual odometry for a monocular camera.pdf:application/pdf}
}

@inproceedings{kerl_robust_2013,
	title = {Robust odometry estimation for {RGB}-{D} cameras},
	booktitle = {2013 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	publisher = {IEEE},
	author = {Kerl, Christian and Sturm, Jürgen and Cremers, Daniel},
	year = {2013},
	pages = {3748--3754},
	file = {Full Text:/home/zz/Zotero/storage/RFZ5MJUT/Kerl et al. - 2013 - Robust odometry estimation for RGB-D cameras.pdf:application/pdf}
}

@article{engel_direct_2017,
	title = {Direct sparse odometry},
	volume = {40},
	number = {3},
	journal = {IEEE transactions on pattern analysis and machine intelligence},
	author = {Engel, Jakob and Koltun, Vladlen and Cremers, Daniel},
	year = {2017},
	note = {Publisher: IEEE},
	pages = {611--625},
	file = {IEEE Xplore Full Text PDF:/home/zz/Zotero/storage/DCPJV2IZ/Engel et al. - 2018 - Direct Sparse Odometry.pdf:application/pdf}
}

@article{mur-artal_orb-slam_2015,
	title = {{ORB}-{SLAM}: a {Versatile} and {Accurate} {Monocular} {SLAM} {System}},
	volume = {31},
	issn = {1552-3098, 1941-0468},
	shorttitle = {{ORB}-{SLAM}},
	url = {http://arxiv.org/abs/1502.00956},
	doi = {10.1109/TRO.2015.2463671},
	abstract = {This paper presents ORB-SLAM, a feature-based monocular SLAM system that operates in real time, in small and large, indoor and outdoor environments. The system is robust to severe motion clutter, allows wide baseline loop closing and relocalization, and includes full automatic initialization. Building on excellent algorithms of recent years, we designed from scratch a novel system that uses the same features for all SLAM tasks: tracking, mapping, relocalization, and loop closing. A survival of the fittest strategy that selects the points and keyframes of the reconstruction leads to excellent robustness and generates a compact and trackable map that only grows if the scene content changes, allowing lifelong operation. We present an exhaustive evaluation in 27 sequences from the most popular datasets. ORB-SLAM achieves unprecedented performance with respect to other state-of-the-art monocular SLAM approaches. For the benefit of the community, we make the source code public.},
	number = {5},
	urldate = {2020-07-16},
	journal = {IEEE Transactions on Robotics},
	author = {Mur-Artal, Raul and Montiel, J. M. M. and Tardos, Juan D.},
	month = oct,
	year = {2015},
	note = {arXiv: 1502.00956},
	keywords = {Computer Science - Robotics, Computer Science - Computer Vision and Pattern Recognition},
	pages = {1147--1163},
	annote = {Comment: 17 pages. 13 figures. IEEE Transactions on Robotics, 2015. Project webpage (videos, code): http://webdiis.unizar.es/{\textasciitilde}raulmur/orbslam/},
	file = {arXiv Fulltext PDF:/home/zz/Zotero/storage/NG98WCCQ/Mur-Artal et al. - 2015 - ORB-SLAM a Versatile and Accurate Monocular SLAM .pdf:application/pdf}
}

@inproceedings{newcombe_kinectfusion_2011,
	title = {{KinectFusion}: {Real}-time dense surface mapping and tracking},
	shorttitle = {{KinectFusion}},
	doi = {10.1109/ISMAR.2011.6092378},
	abstract = {We present a system for accurate real-time mapping of complex and arbitrary indoor scenes in variable lighting conditions, using only a moving low-cost depth camera and commodity graphics hardware. We fuse all of the depth data streamed from a Kinect sensor into a single global implicit surface model of the observed scene in real-time. The current sensor pose is simultaneously obtained by tracking the live depth frame relative to the global model using a coarse-to-fine iterative closest point (ICP) algorithm, which uses all of the observed depth data available. We demonstrate the advantages of tracking against the growing full surface model compared with frame-to-frame tracking, obtaining tracking and mapping results in constant time within room sized scenes with limited drift and high accuracy. We also show both qualitative and quantitative results relating to various aspects of our tracking and mapping system. Modelling of natural scenes, in real-time with only commodity sensor and GPU hardware, promises an exciting step forward in augmented reality (AR), in particular, it allows dense surfaces to be reconstructed in real-time, with a level of detail and robustness beyond any solution yet presented using passive computer vision.},
	booktitle = {2011 10th {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	author = {Newcombe, Richard A. and Izadi, Shahram and Hilliges, Otmar and Molyneaux, David and Kim, David and Davison, Andrew J. and Kohi, Pushmeet and Shotton, Jamie and Hodges, Steve and Fitzgibbon, Andrew},
	month = oct,
	year = {2011},
	keywords = {Cameras, Simultaneous localization and mapping, Real time systems, Tracking, AR, Dense Reconstruction, Depth Cameras, GPU, Image reconstruction, Iterative closest point algorithm, Real-Time, SLAM, Surface reconstruction, Three dimensional displays, Volumetric Representation},
	pages = {127--136},
	file = {Full Text:/home/zz/Zotero/storage/9VUX5JK6/Newcombe et al. - 2011 - KinectFusion Real-time dense surface mapping and .pdf:application/pdf;Submitted Version:/home/zz/Zotero/storage/8UIGIUNE/Newcombe et al. - 2011 - KinectFusion Real-time dense surface mapping and .pdf:application/pdf}
}

@inproceedings{henry_rgb-d_2014,
	title = {{RGB}-{D} mapping: {Using} depth cameras for dense {3D} modeling of indoor environments},
	shorttitle = {{RGB}-{D} mapping},
	booktitle = {Experimental robotics},
	publisher = {Springer},
	author = {Henry, Peter and Krainin, Michael and Herbst, Evan and Ren, Xiaofeng and Fox, Dieter},
	year = {2014},
	pages = {477--491},
	file = {Full Text:/home/zz/Zotero/storage/47HECNWW/Henry et al. - 2014 - RGB-D mapping Using depth cameras for dense 3D mo.pdf:application/pdf}
}

@inproceedings{stuckler_integrating_2012,
	title = {Integrating depth and color cues for dense multi-resolution scene mapping using rgb-d cameras},
	booktitle = {2012 {IEEE} {International} {Conference} on {Multisensor} {Fusion} and {Integration} for {Intelligent} {Systems} ({MFI})},
	publisher = {IEEE},
	author = {Stückler, Jörg and Behnke, Sven},
	year = {2012},
	pages = {162--167},
	file = {Stückler and Behnke - 2012 - Integrating depth and color cues for dense multi-r.pdf:/home/zz/Zotero/storage/DB8EBPRU/Stückler and Behnke - 2012 - Integrating depth and color cues for dense multi-r.pdf:application/pdf}
}

@inproceedings{meilland_dense_2011,
	title = {Dense visual mapping of large scale environments for real-time localisation},
	booktitle = {2011 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	publisher = {IEEE},
	author = {Meilland, Maxime and Comport, Andrew Ian and Rives, Patrick},
	year = {2011},
	pages = {4242--4248},
	file = {Full Text:/home/zz/Zotero/storage/PV9HTFVJ/Meilland et al. - 2011 - Dense visual mapping of large scale environments f.pdf:application/pdf}
}

@inproceedings{engel_large-scale_2015,
	title = {Large-scale direct {SLAM} with stereo cameras},
	booktitle = {2015 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	publisher = {IEEE},
	author = {Engel, Jakob and Stückler, Jörg and Cremers, Daniel},
	year = {2015},
	pages = {1935--1942},
	file = {Full Text:/home/zz/Zotero/storage/4FZJH9MV/Engel et al. - 2015 - Large-scale direct SLAM with stereo cameras.pdf:application/pdf}
}

@article{kappler_real-time_2018,
	title = {Real-time perception meets reactive motion generation},
	volume = {3},
	number = {3},
	journal = {IEEE Robotics and Automation Letters},
	author = {Kappler, Daniel and Meier, Franziska and Issac, Jan and Mainprice, Jim and Cifuentes, Cristina Garcia and Wüthrich, Manuel and Berenz, Vincent and Schaal, Stefan and Ratliff, Nathan and Bohg, Jeannette},
	year = {2018},
	note = {Publisher: IEEE},
	pages = {1864--1871},
	file = {Full Text:/home/zz/Zotero/storage/8FXBDJLP/Kappler et al. - 2018 - Real-time perception meets reactive motion generat.pdf:application/pdf}
}

@article{marquardt_algorithm_1963,
	title = {An algorithm for least-squares estimation of nonlinear parameters},
	volume = {11},
	number = {2},
	journal = {Journal of the society for Industrial and Applied Mathematics},
	author = {Marquardt, Donald W.},
	year = {1963},
	note = {Publisher: SIAM},
	pages = {431--441},
	file = {Full Text:/home/zz/Zotero/storage/3ABX6PT2/Marquardt - 1963 - An algorithm for least-squares estimation of nonli.pdf:application/pdf}
}

@inproceedings{dosovitskiy_flownet_2015,
	title = {Flownet: {Learning} optical flow with convolutional networks},
	shorttitle = {Flownet},
	booktitle = {Proceedings of the {IEEE} international conference on computer vision},
	author = {Dosovitskiy, Alexey and Fischer, Philipp and Ilg, Eddy and Hausser, Philip and Hazirbas, Caner and Golkov, Vladimir and Van Der Smagt, Patrick and Cremers, Daniel and Brox, Thomas},
	year = {2015},
	pages = {2758--2766},
	file = {Full Text:/home/zz/Zotero/storage/TSVTPWCH/Dosovitskiy et al. - 2015 - Flownet Learning optical flow with convolutional .pdf:application/pdf}
}

@inproceedings{ilg_flownet_2017,
	title = {Flownet 2.0: {Evolution} of optical flow estimation with deep networks},
	shorttitle = {Flownet 2.0},
	booktitle = {Proceedings of the {IEEE} conference on computer vision and pattern recognition},
	author = {Ilg, Eddy and Mayer, Nikolaus and Saikia, Tonmoy and Keuper, Margret and Dosovitskiy, Alexey and Brox, Thomas},
	year = {2017},
	pages = {2462--2470},
	file = {Full Text:/home/zz/Zotero/storage/MGXCZX74/Ilg et al. - 2017 - Flownet 2.0 Evolution of optical flow estimation .pdf:application/pdf}
}

@inproceedings{sun_pwc-net_2018,
	title = {Pwc-net: {Cnns} for optical flow using pyramid, warping, and cost volume},
	shorttitle = {Pwc-net},
	booktitle = {Proceedings of the {IEEE} conference on computer vision and pattern recognition},
	author = {Sun, Deqing and Yang, Xiaodong and Liu, Ming-Yu and Kautz, Jan},
	year = {2018},
	pages = {8934--8943},
	file = {Full Text:/home/zz/Zotero/storage/8PM6YANI/Sun et al. - 2018 - Pwc-net Cnns for optical flow using pyramid, warp.pdf:application/pdf}
}

@inproceedings{chang_clkn_2017,
	title = {Clkn: {Cascaded} lucas-kanade networks for image alignment},
	shorttitle = {Clkn},
	booktitle = {Proceedings of the {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Chang, Che-Han and Chou, Chun-Nan and Chang, Edward Y.},
	year = {2017},
	pages = {2213--2221},
	file = {Full Text:/home/zz/Zotero/storage/TZN4URDM/Chang et al. - 2017 - Clkn Cascaded lucas-kanade networks for image ali.pdf:application/pdf}
}

@inproceedings{loop_computing_1999,
	title = {Computing rectifying homographies for stereo vision},
	volume = {1},
	booktitle = {Proceedings. 1999 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({Cat}. {No} {PR00149})},
	publisher = {IEEE},
	author = {Loop, Charles and Zhang, Zhengyou},
	year = {1999},
	pages = {125--131},
	file = {Full Text:/home/zz/Zotero/storage/KJUBBCPW/Loop and Zhang - 1999 - Computing rectifying homographies for stereo visio.pdf:application/pdf}
}

@article{fusiello_compact_2000,
	title = {A compact algorithm for rectification of stereo pairs},
	volume = {12},
	number = {1},
	journal = {Machine vision and applications},
	author = {Fusiello, Andrea and Trucco, Emanuele and Verri, Alessandro},
	year = {2000},
	note = {Publisher: Springer},
	pages = {16--22},
	file = {Full Text:/home/zz/Zotero/storage/3N5PHJKV/Fusiello et al. - 2000 - A compact algorithm for rectification of stereo pa.pdf:application/pdf}
}

@inproceedings{newcombe_dtam_2011,
	title = {{DTAM}: {Dense} tracking and mapping in real-time},
	shorttitle = {{DTAM}},
	booktitle = {2011 international conference on computer vision},
	publisher = {IEEE},
	author = {Newcombe, Richard A. and Lovegrove, Steven J. and Davison, Andrew J.},
	year = {2011},
	pages = {2320--2327},
	file = {Full Text:/home/zz/Zotero/storage/DB24EHDP/Newcombe et al. - 2011 - DTAM Dense tracking and mapping in real-time.pdf:application/pdf}
}

@inproceedings{chang_pyramid_2018,
	title = {Pyramid stereo matching network},
	booktitle = {Proceedings of the {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Chang, Jia-Ren and Chen, Yong-Sheng},
	year = {2018},
	pages = {5410--5418},
	file = {Full Text:/home/zz/Zotero/storage/5IAZA56H/Chang and Chen - 2018 - Pyramid stereo matching network.pdf:application/pdf}
}

@inproceedings{yao_mvsnet_2018,
	title = {Mvsnet: {Depth} inference for unstructured multi-view stereo},
	shorttitle = {Mvsnet},
	booktitle = {Proceedings of the {European} {Conference} on {Computer} {Vision} ({ECCV})},
	author = {Yao, Yao and Luo, Zixin and Li, Shiwei and Fang, Tian and Quan, Long},
	year = {2018},
	pages = {767--783},
	file = {Full Text:/home/zz/Zotero/storage/FYJ6BRHQ/Yao et al. - 2018 - Mvsnet Depth inference for unstructured multi-vie.pdf:application/pdf}
}

@inproceedings{godard_unsupervised_2017,
	title = {Unsupervised monocular depth estimation with left-right consistency},
	booktitle = {Proceedings of the {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Godard, Clément and Mac Aodha, Oisin and Brostow, Gabriel J.},
	year = {2017},
	pages = {270--279},
	file = {Full Text:/home/zz/Zotero/storage/27LSXLAH/Godard et al. - 2017 - Unsupervised monocular depth estimation with left-.pdf:application/pdf}
}

@inproceedings{huang_least-squares_1986,
	title = {Least-squares estimation of motion parameters from 3-{D} point correspondences},
	volume = {10},
	booktitle = {Proc. {IEEE} {Conf}. {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Huang, T. S. and Blostein, S. D. and Margerum, E. A.},
	year = {1986},
	pages = {112--115},
	file = {Huang et al. - 1986 - Least-squares estimation of motion parameters from.pdf:/home/zz/Zotero/storage/GD83P2EK/Huang et al. - 1986 - Least-squares estimation of motion parameters from.pdf:application/pdf}
}

@article{lepetit_epnp_2009,
	title = {Epnp: {An} accurate o (n) solution to the pnp problem},
	volume = {81},
	shorttitle = {Epnp},
	number = {2},
	journal = {International journal of computer vision},
	author = {Lepetit, Vincent and Moreno-Noguer, Francesc and Fua, Pascal},
	year = {2009},
	note = {Publisher: Springer},
	pages = {155},
	file = {Full Text:/home/zz/Zotero/storage/HHUXZF2M/Lepetit et al. - 2009 - Epnp An accurate o (n) solution to the pnp proble.pdf:application/pdf}
}

@inproceedings{zheng_revisiting_2013,
	title = {Revisiting the pnp problem: {A} fast, general and optimal solution},
	shorttitle = {Revisiting the pnp problem},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Computer} {Vision}},
	author = {Zheng, Yinqiang and Kuang, Yubin and Sugimoto, Shigeki and Astrom, Kalle and Okutomi, Masatoshi},
	year = {2013},
	pages = {2344--2351},
	file = {Full Text:/home/zz/Zotero/storage/P23UQW9A/Zheng et al. - 2013 - Revisiting the pnp problem A fast, general and op.pdf:application/pdf}
}

@article{longuet-higgins_computer_1981,
	title = {A computer algorithm for reconstructing a scene from two projections},
	volume = {293},
	number = {5828},
	journal = {Nature},
	author = {Longuet-Higgins, H. Christopher},
	year = {1981},
	note = {Publisher: Springer},
	pages = {133--135},
	file = {Full Text:/home/zz/Zotero/storage/A5F3CBIC/Longuet-Higgins - 1981 - A computer algorithm for reconstructing a scene fr.pdf:application/pdf}
}

@article{nister_efficient_2004,
	title = {An efficient solution to the five-point relative pose problem},
	volume = {26},
	number = {6},
	journal = {IEEE transactions on pattern analysis and machine intelligence},
	author = {Nistér, David},
	year = {2004},
	note = {Publisher: IEEE},
	pages = {756--770},
	file = {Full Text:/home/zz/Zotero/storage/K28XDR8U/Nistér - 2004 - An efficient solution to the five-point relative p.pdf:application/pdf}
}

@article{hartley_defense_1997,
	title = {In defense of the eight-point algorithm},
	volume = {19},
	number = {6},
	journal = {IEEE Transactions on pattern analysis and machine intelligence},
	author = {Hartley, Richard I.},
	year = {1997},
	note = {Publisher: IEEE},
	pages = {580--593},
	file = {Full Text:/home/zz/Zotero/storage/842WS65M/Hartley - 1997 - In defense of the eight-point algorithm.pdf:application/pdf}
}

@book{ma_invitation_2012,
	title = {An invitation to 3-d vision: from images to geometric models},
	volume = {26},
	shorttitle = {An invitation to 3-d vision},
	publisher = {Springer Science \& Business Media},
	author = {Ma, Yi and Soatto, Stefano and Kosecka, Jana and Sastry, S. Shankar},
	year = {2012},
	file = {Full Text:/home/zz/Zotero/storage/6ICP6N4Z/Ma et al. - 2012 - An invitation to 3-d vision from images to geomet.pdf:application/pdf}
}

@inproceedings{bloesch_robust_2015,
	title = {Robust visual inertial odometry using a direct {EKF}-based approach},
	booktitle = {2015 {IEEE}/{RSJ} international conference on intelligent robots and systems ({IROS})},
	publisher = {IEEE},
	author = {Bloesch, Michael and Omari, Sammy and Hutter, Marco and Siegwart, Roland},
	year = {2015},
	pages = {298--304},
	file = {Full Text:/home/zz/Zotero/storage/RMDQ8F3K/Bloesch et al. - 2015 - Robust visual inertial odometry using a direct EKF.pdf:application/pdf}
}

@book{thrun_probalistic_2006,
	title = {Probalistic robotics},
	author = {Thrun, Sebastian and Burgard, Wolfram and Fox, Dieter},
	year = {2006},
	note = {Publisher: Emerald Group Publishing Limited},
	file = {Thrun et al. - 2006 - Probalistic robotics.pdf:/home/zz/Zotero/storage/WHYYKEDD/Thrun et al. - 2006 - Probalistic robotics.pdf:application/pdf}
}

@book{murphy_machine_2012,
	title = {Machine learning: a probabilistic perspective},
	shorttitle = {Machine learning},
	publisher = {MIT press},
	author = {Murphy, Kevin P.},
	year = {2012},
	file = {Murphy - 2012 - Machine learning a probabilistic perspective.pdf:/home/zz/Zotero/storage/DJZIZ6CE/Murphy - 2012 - Machine learning a probabilistic perspective.pdf:application/pdf}
}

@inproceedings{choi_rgb-d_2013,
	title = {{RGB}-{D} object tracking: {A} particle filter approach on {GPU}},
	shorttitle = {{RGB}-{D} object tracking},
	booktitle = {2013 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	publisher = {IEEE},
	author = {Choi, Changhyun and Christensen, Henrik I.},
	year = {2013},
	pages = {1084--1091},
	file = {Choi and Christensen - 2013 - RGB-D object tracking A particle filter approach .pdf:/home/zz/Zotero/storage/JU8BRCU3/Choi and Christensen - 2013 - RGB-D object tracking A particle filter approach .pdf:application/pdf}
}

@inproceedings{van_der_merwe_unscented_2001,
	title = {The unscented particle filter},
	booktitle = {Advances in neural information processing systems},
	author = {Van Der Merwe, Rudolph and Doucet, Arnaud and De Freitas, Nando and Wan, Eric A.},
	year = {2001},
	pages = {584--590},
	file = {Full Text:/home/zz/Zotero/storage/LP2ARQ3V/Van Der Merwe et al. - 2001 - The unscented particle filter.pdf:application/pdf}
}

@incollection{doucet_introduction_2001,
	title = {An introduction to sequential {Monte} {Carlo} methods},
	booktitle = {Sequential {Monte} {Carlo} methods in practice},
	publisher = {Springer},
	author = {Doucet, Arnaud and De Freitas, Nando and Gordon, Neil},
	year = {2001},
	pages = {3--14},
	file = {Full Text:/home/zz/Zotero/storage/PTYD89ZG/Doucet et al. - 2001 - An introduction to sequential Monte Carlo methods.pdf:application/pdf}
}

@article{civera_inverse_2008,
	title = {Inverse depth parametrization for monocular {SLAM}},
	volume = {24},
	number = {5},
	journal = {IEEE transactions on robotics},
	author = {Civera, Javier and Davison, Andrew J. and Montiel, JM Martinez},
	year = {2008},
	note = {Publisher: IEEE},
	pages = {932--945},
	file = {Full Text:/home/zz/Zotero/storage/SV7TL5EJ/Civera et al. - 2008 - Inverse depth parametrization for monocular SLAM.pdf:application/pdf}
}

@article{faugeras_motion_1988,
	title = {Motion and structure from motion in a piecewise planar environment},
	volume = {2},
	number = {03},
	journal = {International Journal of Pattern Recognition and Artificial Intelligence},
	author = {Faugeras, Olivier D. and Lustman, Francis},
	year = {1988},
	note = {Publisher: World Scientific},
	pages = {485--508},
	file = {Full Text:/home/zz/Zotero/storage/SV2SRQVZ/Faugeras and Lustman - 1988 - Motion and structure from motion in a piecewise pl.pdf:application/pdf}
}

@article{horn_closed-form_1987,
	title = {Closed-form solution of absolute orientation using unit quaternions},
	volume = {4},
	number = {4},
	journal = {Josa a},
	author = {Horn, Berthold KP},
	year = {1987},
	note = {Publisher: Optical Society of America},
	pages = {629--642},
	file = {Full Text:/home/zz/Zotero/storage/EBGI2NK5/Horn - 1987 - Closed-form solution of absolute orientation using.pdf:application/pdf}
}

@article{papazov_rigid_2012,
	title = {Rigid {3D} geometry matching for grasping of known objects in cluttered scenes},
	volume = {31},
	number = {4},
	journal = {The International Journal of Robotics Research},
	author = {Papazov, Chavdar and Haddadin, Sami and Parusel, Sven and Krieger, Kai and Burschka, Darius},
	year = {2012},
	note = {Publisher: SAGE Publications Sage UK: London, England},
	pages = {538--553},
	file = {Full Text:/home/zz/Zotero/storage/BRYW8MWX/Papazov et al. - 2012 - Rigid 3D geometry matching for grasping of known o.pdf:application/pdf}
}

@article{xiang_posecnn_2017,
	title = {Posecnn: {A} convolutional neural network for 6d object pose estimation in cluttered scenes},
	shorttitle = {Posecnn},
	journal = {arXiv preprint arXiv:1711.00199},
	author = {Xiang, Yu and Schmidt, Tanner and Narayanan, Venkatraman and Fox, Dieter},
	year = {2017},
	file = {Full Text:/home/zz/Zotero/storage/FYR3L49V/Xiang et al. - 2017 - Posecnn A convolutional neural network for 6d obj.pdf:application/pdf}
}

@article{endres_3-d_2013,
	title = {3-{D} mapping with an {RGB}-{D} camera},
	volume = {30},
	number = {1},
	journal = {IEEE transactions on robotics},
	author = {Endres, Felix and Hess, Jürgen and Sturm, Jürgen and Cremers, Daniel and Burgard, Wolfram},
	year = {2013},
	note = {Publisher: IEEE},
	pages = {177--187},
	file = {Full Text:/home/zz/Zotero/storage/I6QLFMVQ/Endres et al. - 2013 - 3-D mapping with an RGB-D camera.pdf:application/pdf}
}

@article{hornung_octomap_2013,
	title = {{OctoMap}: {An} efficient probabilistic {3D} mapping framework based on octrees},
	volume = {34},
	shorttitle = {{OctoMap}},
	number = {3},
	journal = {Autonomous robots},
	author = {Hornung, Armin and Wurm, Kai M. and Bennewitz, Maren and Stachniss, Cyrill and Burgard, Wolfram},
	year = {2013},
	note = {Publisher: Springer},
	pages = {189--206},
	file = {Full Text:/home/zz/Zotero/storage/DAYAW9P8/Hornung et al. - 2013 - OctoMap An efficient probabilistic 3D mapping fra.pdf:application/pdf}
}

@article{niesner_real-time_2013,
	title = {Real-time {3D} reconstruction at scale using voxel hashing},
	volume = {32},
	number = {6},
	journal = {ACM Transactions on Graphics (ToG)},
	author = {Nießner, Matthias and Zollhöfer, Michael and Izadi, Shahram and Stamminger, Marc},
	year = {2013},
	note = {Publisher: ACM New York, NY, USA},
	pages = {1--11},
	file = {Full Text:/home/zz/Zotero/storage/4QNR2RYC/Nießner et al. - 2013 - Real-time 3D reconstruction at scale using voxel h.pdf:application/pdf}
}

@inproceedings{keller_real-time_2013,
	title = {Real-time 3d reconstruction in dynamic scenes using point-based fusion},
	booktitle = {2013 {International} {Conference} on {3D} {Vision}-{3DV} 2013},
	publisher = {IEEE},
	author = {Keller, Maik and Lefloch, Damien and Lambers, Martin and Izadi, Shahram and Weyrich, Tim and Kolb, Andreas},
	year = {2013},
	pages = {1--8},
	file = {Full Text:/home/zz/Zotero/storage/7ZKKFQ7T/Keller et al. - 2013 - Real-time 3d reconstruction in dynamic scenes usin.pdf:application/pdf}
}

@inproceedings{whelan_elasticfusion_2015,
	title = {{ElasticFusion}: {Dense} {SLAM} without a pose graph},
	shorttitle = {{ElasticFusion}},
	publisher = {Robotics: Science and Systems},
	author = {Whelan, Thomas and Leutenegger, Stefan and Salas-Moreno, R. and Glocker, Ben and Davison, Andrew},
	year = {2015},
	file = {Full Text:/home/zz/Zotero/storage/WYI79UM3/Whelan et al. - 2015 - ElasticFusion Dense SLAM without a pose graph.pdf:application/pdf}
}

@article{stuckler_efficient_2015,
	title = {Efficient dense rigid-body motion segmentation and estimation in {RGB}-{D} video},
	volume = {113},
	number = {3},
	journal = {International Journal of Computer Vision},
	author = {Stückler, Jörg and Behnke, Sven},
	year = {2015},
	note = {Publisher: Springer},
	pages = {233--245},
	file = {Full Text:/home/zz/Zotero/storage/5Y8UEFVV/Stückler and Behnke - 2015 - Efficient dense rigid-body motion segmentation and.pdf:application/pdf}
}

@inproceedings{strecke_em-fusion_2019,
	title = {{EM}-fusion: {Dynamic} object-level {SLAM} with probabilistic data association},
	shorttitle = {{EM}-fusion},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Computer} {Vision}},
	author = {Strecke, Michael and Stuckler, Jorg},
	year = {2019},
	pages = {5865--5874},
	file = {Full Text:/home/zz/Zotero/storage/WCTC37BN/Strecke and Stuckler - 2019 - EM-fusion Dynamic object-level SLAM with probabil.pdf:application/pdf}
}

@inproceedings{engelmann_joint_2016,
	title = {Joint object pose estimation and shape reconstruction in urban street scenes using {3D} shape priors},
	booktitle = {German {Conference} on {Pattern} {Recognition}},
	publisher = {Springer},
	author = {Engelmann, Francis and Stückler, Jörg and Leibe, Bastian},
	year = {2016},
	pages = {219--230},
	file = {Engelmann et al. - 2016 - Joint object pose estimation and shape reconstruct.pdf:/home/zz/Zotero/storage/3NP6WPDU/Engelmann et al. - 2016 - Joint object pose estimation and shape reconstruct.pdf:application/pdf}
}

@article{wang_directshape_2019,
	title = {{DirectShape}: {Direct} {Photometric} {Alignment} of {Shape} {Priors} for {Visual} {Vehicle} {Pose} and {Shape} {Estimation}},
	shorttitle = {{DirectShape}},
	journal = {arXiv preprint arXiv:1904.10097},
	author = {Wang, Rui and Yang, Nan and Stückler, Jörg and Cremers, Daniel},
	year = {2019},
	file = {Full Text:/home/zz/Zotero/storage/6H3LIKMQ/Wang et al. - 2019 - DirectShape Direct Photometric Alignment of Shape.pdf:application/pdf}
}

@article{campos_orb-slam3_2020,
	title = {{ORB}-{SLAM3}: {An} {Accurate} {Open}-{Source} {Library} for {Visual}, {Visual}-{Inertial} and {Multi}-{Map} {SLAM}},
	shorttitle = {{ORB}-{SLAM3}},
	url = {http://arxiv.org/abs/2007.11898},
	abstract = {This paper presents ORB-SLAM3, the first system able to perform visual, visual-inertial and multi-map SLAM with monocular, stereo and RGB-D cameras, using pin-hole and fisheye lens models. The first main novelty is a feature-based tightly-integrated visual-inertial SLAM system that fully relies on Maximum-a-Posteriori (MAP) estimation, even during the IMU initialization phase. The result is a system that operates robustly in real-time, in small and large, indoor and outdoor environments, and is 2 to 5 times more accurate than previous approaches. The second main novelty is a multiple map system that relies on a new place recognition method with improved recall. Thanks to it, ORB-SLAM3 is able to survive to long periods of poor visual information: when it gets lost, it starts a new map that will be seamlessly merged with previous maps when revisiting mapped areas. Compared with visual odometry systems that only use information from the last few seconds, ORB-SLAM3 is the first system able to reuse in all the algorithm stages all previous information. This allows to include in bundle adjustment co-visible keyframes, that provide high parallax observations boosting accuracy, even if they are widely separated in time or if they come from a previous mapping session. Our experiments show that, in all sensor configurations, ORB-SLAM3 is as robust as the best systems available in the literature, and significantly more accurate. Notably, our stereo-inertial SLAM achieves an average accuracy of 3.6 cm on the EuRoC drone and 9 mm under quick hand-held motions in the room of TUM-VI dataset, a setting representative of AR/VR scenarios. For the benefit of the community we make public the source code.},
	urldate = {2020-07-31},
	journal = {arXiv:2007.11898 [cs]},
	author = {Campos, Carlos and Elvira, Richard and Rodríguez, Juan J. Gómez and Montiel, José M. M. and Tardós, Juan D.},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.11898},
	keywords = {Computer Science - Robotics},
	file = {arXiv Fulltext PDF:/home/zz/Zotero/storage/8ZNYA9JY/Campos et al. - 2020 - ORB-SLAM3 An Accurate Open-Source Library for Vis.pdf:application/pdf}
}

@book{barfoot_state_2017,
	title = {State estimation for robotics},
	publisher = {Cambridge University Press},
	author = {Barfoot, Timothy D.},
	year = {2017},
	file = {Full Text:/home/zz/Zotero/storage/EGQ8WNQC/Barfoot - 2017 - State estimation for robotics.pdf:application/pdf}
}

@inproceedings{park_illumination_2017,
	title = {Illumination change robustness in direct visual slam},
	booktitle = {2017 {IEEE} international conference on robotics and automation ({ICRA})},
	publisher = {IEEE},
	author = {Park, Seonwook and Schöps, Thomas and Pollefeys, Marc},
	year = {2017},
	pages = {4523--4530},
	file = {Full Text:/home/zz/Zotero/storage/IIKT3QNX/Park et al. - 2017 - Illumination change robustness in direct visual sl.pdf:application/pdf}
}

@book{hartley_multiple_2003,
	title = {Multiple view geometry in computer vision},
	publisher = {Cambridge university press},
	author = {Hartley, Richard and Zisserman, Andrew},
	year = {2003},
	file = {Multiple View Geometry in Computer Vision (Second Edition).pdf:/home/zz/Zotero/storage/BF9EIFS3/Multiple View Geometry in Computer Vision (Second Edition).pdf:application/pdf}
}

@book{_slam_2017,
	address = {北京},
	title = {{视觉SLAM十四讲}：从理论到实践},
	isbn = {978-7-121-31104-8},
	publisher = {电子工业出版社},
	author = {高, 翔 and 张, 涛},
	month = mar,
	year = {2017},
	file = {翔 and 涛 - 2017 - 视觉SLAM十四讲：从理论到实践.pdf:/home/zz/Zotero/storage/JR2KDYV4/翔 and 涛 - 2017 - 视觉SLAM十四讲：从理论到实践.pdf:application/pdf}
}

@book{hartley__2002,
	edition = {第一版},
	title = {计算机视觉中的多视图几何},
	isbn = {7-81052-503-4},
	publisher = {安徽大学出版社},
	author = {Hartley, Richard and Zisserman, Andrew},
	translator = {韦, 穗 and 杨, 尚俊 and 章, 权兵 and 胡, 茂林},
	year = {2002},
	file = {Hartley and Zisserman - 2002 - 计算机视觉中的多视图几何.pdf:/home/zz/Zotero/storage/F3BK8L89/Hartley and Zisserman - 2002 - 计算机视觉中的多视图几何.pdf:application/pdf}
}

@book{thrun__2017,
	edition = {第一版},
	title = {概率机器人},
	isbn = {978-7-111-50437-5},
	author = {Thrun, Sebastian and Burgard, Wolfram and Fox, Dieter},
	translator = {曾, 红玉 and 谭, 志 and 史, 晓霞},
	year = {2017},
	file = {Thrun et al. - 概率机器人.pdf:/home/zz/Zotero/storage/GF6ZRMWL/Thrun et al. - 概率机器人.pdf:application/pdf}
}

@book{barfoot__2018,
	title = {机器人学的状态估计},
	author = {Barfoot, Timothy D.},
	translator = {高, 翔 and 颜, 沁睿 and 刘, 富强 and 郭, 玉峰 and 秦, 超 and 谢, 晓佳},
	year = {2018},
	file = {Barfoot - 机器人学的状态估计.pdf:/home/zz/Zotero/storage/VE9DJIQY/Barfoot - 机器人学的状态估计.pdf:application/pdf}
}
